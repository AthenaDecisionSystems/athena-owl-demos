{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#demonstration-repository","title":"Demonstration repository","text":"<p>This repository includes pre-defined demonstrations that can be used with different decision services and different use cases, and instructions and tools to jump start your own solution.</p> Name Goal IBU Insurance A chatbot to help IBU Insurance\u2019s customer service representatives manage customer complaints IBU MiniLoan A demonstration of Agentic solution with IBM ODM Miniloan sample <p>To watch the IBU Insurance demonstration video  on YouTube.</p> <p></p> <p>If you want to develop your own demonstration or jump start your own solution see these instructions.</p>"},{"location":"#contact-us","title":"Contact us","text":"<p>Athena is here to help you seamlessly integrate this innovative framework into your operations. For a customized proof of concept or production deployment, feel free to reach out to the expert team at Athena Decision Systems or email Athena. With deep industry knowledge and tailored solutions, Athena will ensure a smooth and successful implementation that drives tangible value for your business.</p>"},{"location":"build_sol/","title":"Build your own solution","text":""},{"location":"build_sol/#build-solution","title":"Build solution","text":"Version <p>Created 06.2024 - Updated 07/10/24</p> <p>Creating a new solution using the owl framework should be straightforward at it uses yaml manifests at its core, but potential complexity may depend on the level of the requirements to integrate with external services. </p> <p>To get started consider the scope of the demonstration and assess if you need to:</p> <ul> <li>Use a specific LLM backend</li> <li>Have an existing decision service available to be used or if you need to develop a new one. A new decision service means new rules and a new data model for the rule processing. Rule discovery and analysis may take some time as the approach is to model knowledge from workers with rules and data model.</li> <li>The design of the tool calling may become more complex when the number of tool grow, and when some potential user's query may not be easy to map to tool.</li> </ul> <p>Recall that an Hybrid-AI solution includes as set of components working together to deliver more reliable results, higher accuracy with stateful persistence:</p> <p></p> <p>We recommend reading the design document, the architecture presentation and some tutorials to create agent.</p>"},{"location":"build_sol/#jump-start-your-own-solution","title":"Jump start your own solution","text":"<p>As a first tutorial, we will use an existing decision service deployed to the IBM ODM decision server.</p>"},{"location":"build_sol/#git-repositories","title":"Git repositories","text":"<p>We encourage you, to fork the OWL core repository https://github.com/AthenaDecisionSystems/athena-owl-core</p> <p></p> <p>And the demonstration repository: https://github.com/AthenaDecisionSystems/athena-owl-demos</p>"},{"location":"build_sol/#pre-requisites","title":"Pre-requisites","text":"<p>The following tools and environments are needed:</p> <ul> <li>Python 3.11 or 3.12, using a virtual environment</li> <li>Get a the API keys for the different LLM you want to use in your solution: WatsonX.AI , OpenAI Anthropic, Mistral, ... and use the <code>/demo_tmpl/.env_tmpl</code> file to persist those API KEYS, rename the file as <code>.env</code> and move it into the demonstration folder you want to use or the new folder for your solution.</li> </ul> <pre><code>cp ../demo_tmpl/.env_tmpl .env\n</code></pre>"},{"location":"build_sol/#create-project","title":"Create project","text":"<p>The following steps will soon be automatized with scripts and tools, but as of now, they are manual (sorry):</p> <ul> <li>Create a folder for your project: <code>IBM-MiniLoan-demo</code> in the athena-owl-demos folder. </li> <li>Copy the project template to the new folder:</li> </ul> <pre><code>cp -r demo_tmpl/ My-MiniLoan-demo\ncd My-MiniLoan-demo\n</code></pre> <ul> <li>Create and Start a Python virtual environment</li> </ul> <pre><code>python -m venv .venv\n# For windows PC\nsource .venv/Scripts/activate\n# For unix based PC\nsource .venv/bin/activate\n</code></pre> <p>The creation is needed only for the first time.</p> <ul> <li>Install the Python modules needed for the solution</li> </ul> <pre><code>pip -r ibu-backend/src/requirements.txt\n</code></pre>"},{"location":"build_sol/#build-the-object-model-for-decision-service","title":"Build the object model for decision service","text":"<p>The decision service exposes an REST API with an Open API document. From this document it is easy to get the data model and create Python Pydantic objects from it. Here are the steps:</p> <ol> <li>Access the ODM Developer Edition console at http://localhost:9060/, select he decision server console</li> <li> <p>Navigate to the RuleApp &gt; Ruleset in the <code>Explorer</code> tab that you want to call:</p> <p></p> </li> <li> <p>Get the OpenAI yaml document and download it to a project folder <code>ibu_backend/src/openapi</code>.</p> <p></p> </li> <li> <p>Run the command to build the pydantic model</p> </li> </ol> <pre><code>datamodel-codegen  --input MydeploymentMiniloan_ServiceRulesetDecisionService.yaml --input-file-type openapi --output ../ibu/itg/ds/pydantic_generated_model.py\n</code></pre> <p>Below is an extract of the generated code, and an link to the code.</p> <pre><code>class Borrower(BaseModel):\n    name: Optional[str] = None\n    creditScore: Optional[int] = None\n    yearlyIncome: Optional[int] = None\n\n\nclass Loan(BaseModel):\n    amount: Optional[int] = None\n    duration: Optional[int] = None\n    yearlyInterestRate: Optional[float] = None\n    yearlyRepayment: Optional[int] = None\n    approved: Optional[bool] = True\n    messages: Optional[List[str]] = []\n</code></pre> <p>If needed review the input and optional fields as some empty attribute may generate null pointer exception in the rules For example approved need to be initialized to True and messages to be an empty array instead of None:</p> <pre><code>    yearlyRepayment: Optional[int] = None\n    approved: Optional[bool] = True\n    messages: Optional[List[str]] = []\n</code></pre> <p>Those steps need to be done each time there are changes to the ODM eXecutable Object Model. If this model is stable, those steps are done only one time.</p>"},{"location":"build_sol/#build-the-python-function-to-call-odm","title":"Build the python function to call ODM","text":"LLM and Tool calling <p>OpenAI has started the initiative of function calling and now most of the major proprietary or open source LLM model supports tool calling. In the LLM tool calling mechanism the prompt is enhanced with information about the function signature. For example the LLM will see the following signature and will prepare the argument from the user's query </p><pre><code>def get_client_by_name(first_name: str, last_name: str)\n</code></pre> <p>Here is an example of LLM trace showing the preparation of the data: </p><pre><code>Invoking: `get_client_by_name` with `{'first_name': 'Robert', 'last_name': 'Smith'}`\n</code></pre> <p>In the code template <code>src/ibu/llm/tools/client_tools.py</code> define a new function to expose a set of parameters the LLM will be able to extract from unstructured query text:</p> <pre><code>def assess_loan_app_with_decision(loan_amount: int, duration: int,   first_name: str, last_name: str):\n    loanRequest= Loan(duration=duration, amount=loan_amount)\n    borrower =  build_or_get_loan_client_repo().get_client_by_name(first_name=first_name, last_name=last_name)\n    ds_request = Request(__DecisionID__= str(uuid.uuid4),borrower=borrower, loan=loanRequest)\n    payload: str = ds_request.model_dump_json()\n    return callRuleExecutionServer(payload)\n</code></pre> <p>The code needs to prepare the data to call IBM ODM, using the Pydantic objects created above. </p>"},{"location":"build_sol/#define-tools","title":"Define Tools","text":"<p>The classical common integration is when the solution needs to get data from an existing database or better a microservice managing a specific business entity. In this case the solution leverage a python function that can remote call the microservice URL using library like <code>requests</code>.</p> <p>For short demonstration you may need to implement some mockup repository that could be integrated into the demo run time. The template folder includes such in memory repository. You need to update with your own data (See this file loanapp_borrower_repo_mock.py).</p> <pre><code>def initialize_client_db(self):\n        self.add_client(Borrower(name = \"robert dupont\",\n                            yearlyIncome = 50000,\n                            creditScore = 180\n                            ))\n    # ...\n</code></pre>"},{"location":"build_sol/#adding-a-function-as-tool","title":"Adding a function as tool","text":"<p>As some Owl assistants are using LangGraph for agent orchestration, we will use LangChain tools API to define function calling.</p> <p>There are three ways to do so with LangChain: function annotation, using a factory function or class sub-classing. </p> <p>The tool annotation is the simplest approach. The following declaration uses annotation, and the argument names, type and comment description are very important as they will be injected as context in the prompt to the LLM. Be sure to be short but brings semantic so the LLM can decide which function to call and what parameters to extract such as the first and last names.</p> <pre><code>@tool\ndef get_client_by_name(first_name: str, last_name: str) -&gt; str | None:\n    \"\"\"get borrower client information given his or her name\"\"\"\n    return build_or_get_loan_client_repo().get_client_by_name_json(first_name,last_name)\n</code></pre>"},{"location":"build_sol/#declaring-the-tool-in-yaml","title":"Declaring the tool in yaml","text":"<p>Update the <code>tools.yaml</code> file in the config folder:</p> <pre><code>ibu_client_by_name:\n  tool_id: ibu_client_by_name\n  tool_class_name: 'ibu.llm.tools.client_tools'\n  tool_description: 'get client information given his first and last name'\n  tool_fct_name: get_client_by_name\n</code></pre> Behind the scene <p>The tool factory implementation </p>"},{"location":"build_sol/#define-prompt","title":"Define prompt","text":"<p>Prompts are defined in <code>prompts.json</code> file. </p>"},{"location":"build_sol/#define-assistant","title":"Define Assistant","text":"<p>Add the following base declaration for the main Assistant of the solution. One Assistant per use case.</p> <pre><code>ibu_assistant:\n  assistant_id: ibu_assistant\n  class_name: athena.llm.assistants.BaseAssistant.BaseAssistant\n  description: A default assistant that uses LLM, and local defined tools like get borrower, and next best action\n  name: IBU Loan App assistant\n  agent_id: ibu_agent\n</code></pre> <p>The two important properties are the <code>class_name</code> and the <code>agent_id</code>.</p> <p>The BaseAssistant class name is coming from Owl Agent core library. </p> <p>This is the LangGraph flow with tool and LLM. The graph looks like in the following figure:</p> <p></p>"},{"location":"build_sol/#define-agent","title":"Define Agent","text":""},{"location":"build_sol/#integration-tests","title":"Integration tests","text":""},{"location":"build_sol/#custom-user-interface","title":"Custom user interface","text":"<p>You can use the OWL Front End user interface as is and can slightly customize it via environment variables which can be set in the docker-compose file:</p> <pre><code>  owl-frontend:\n    hostname: owl-frontend\n    image: jbcodeforce/athena-owl-frontend:latest \n    container_name: owl-frontend\n    ports:\n      - 3000:80\n    environment:\n      - REACT_APP_OWL_AGENT_NAME=\"YOUR DEMO NAME\"\n      - REACT_APP_BACKEND_URL=http://localhost:8000/api/v1/\n      - REACT_APP_ASSISTANT_ID_WITH_RULES='ibu_assistant'\n      - REACT_APP_ASSISTANT_ID_WITHOUT_RULES='ibu_assistant_limited'\n      - REACT_APP_DEMO_TEXT=\"ONE SENTENCE to use for the demo\"\n</code></pre>"},{"location":"build_sol/#troubleshooting","title":"Troubleshooting","text":"<p>Access to the logs of decision server or owl backend server by doing</p> <pre><code>docker logs owl-backend\ndocker logs decisionsvc\n</code></pre>"},{"location":"build_sol/#exception-when-starting-odm-decision-server","title":"Exception when starting ODM decision server","text":"<p>The trace of the decision service may log an exception of sequence number already created. </p> <pre><code> org.h2.jdbc.JdbcSQLSyntaxErrorException: Sequence \"SYSTEM_SEQUENCE_AAD2612D_FF17_4435_A436_6D4A63BF6D6E\" already exists; SQL statement:\n</code></pre> <p>This may come from previous execution on a new database. Just deleting the <code>decisions/persistence</code> folder, and restarting the decision server solved the problem.</p>"},{"location":"insurance/","title":"IBU Insurance","text":""},{"location":"insurance/#ibu-insurance","title":"IBU Insurance","text":"Version <p>Created 05/2024. Updated 07/11/2024 - STILL UNDER WORK</p> <p>The IBU insurance demonstration illustrates the integration with data manager service, a decision service, a vector store and a LLM as shown in the figure below:</p> <p></p> <ul> <li> <p> Set up in 5 minutes</p> <p>create a <code>.env</code> file under IBU-insurance-demo with the API key for the LLM you want to use. See the file template in <code>demo_tmpl/.env_tmpl</code>. Then cd IBU-insurance-demo/deployment/local &amp;&amp; docker-compose up -d </p> <p>and get up and running in minutes. </p> <p> Demonstration Script</p> </li> <li> <p> Develop around this demo</p> <p>Tune the content of this demonstration or deep dive into how it is built.  Work on code</p> </li> <li> <p> Open Source, Apache</p> <p>Owl Agent and demonstration are licensed under Apache and available on GitHub</p> <p> License</p> </li> </ul>"},{"location":"insurance/#goals","title":"Goals","text":"<p>The IBU Insurance agent chatbot helps IBU Insurance\u2019s customer service representatives manage customer complaints about their claims handling. The chatbot is used by the customer service reps when a customer calls or writes with a complaint.</p> <p>The chatbot should bring consistent responses and actionable decisions, which improves the complain management by more than 27% and improve the quality responses by 35% while reducing the cost by around 60%. </p> <p></p> <p>Link to video</p>"},{"location":"insurance/#insurance-context","title":"Insurance context","text":"<p>In most insurance organization we may find the following roles Involved in Complaint Handling process:</p> <p></p> <p>The AI assistant will help the contact center agents.</p> <p>In the insurance industry the strategy to better manage customers is based on a metric called the Customer LifeTime Value or CLTV. The higher the value, the better will be the customer support, with some personalized service with dedicated advisor. At the lower range, the insurance may let their customers go away as it might actually reduce adverse selection and improve the overall profitability of the company. Finally for the bigger part of the customer profile, the company may want to retain them but using some retention effort at the minimum cost. </p> <p>As part of the automated chatbot integration the business policy may first evaluate the risk of churn and then reassign the interaction to the retention department if needed.</p>"},{"location":"insurance/#build-for-demonstration","title":"Build for demonstration","text":"<p>For development purpose, build the DataManager microservice image:</p> Under the datamgt folder<pre><code>./build/buildImage.sh\n</code></pre> <p>The docker images for the DataManager microservice, the chatbot frontend and for the OWL Backend are available on docker hub.</p> <p></p> <p>The docker compose starts by downloading docker images from Docker Hub. Those images were built on intel based architecture. If you run on arm architecture like the MAC M family, you need to build the owl backend and owl front end images (See the instructions here). </p>"},{"location":"insurance/#run-locally","title":"Run locally","text":"<ul> <li>Get a the API keys for the different LLM you want to use in your solution: WatsonX.AI , OpenAI Anthropic, Mistral, ... and use the <code>/demo_tmpl/.env_tmpl</code> file to persist those API KEYS, rename the file as <code>.env</code> and move it the miniloan demonstration folder.</li> </ul> <pre><code># under IBU-insurance-demo\ncp ../demo_tmpl/.env_tmpl .env\n</code></pre> <p>To start all the components of the solution like the owl_backend, the owl_frontend, the data manager, postgresql database, and the ODM decision service, use the docker compose file locally under the <code>IBU-insurance-demo/deployment/local/</code> folder. </p> <ul> <li>Start all the services:</li> </ul> IBU-insurance-demo/deployment/local/ folder.<pre><code>docker-compose up -d \n</code></pre> <p>The first time you launch it, it may take some time as it downloads the needed docker images from docker hub.</p> <ul> <li>Verify that the six containers are running:</li> </ul> <pre><code>docker ps\n</code></pre> <pre><code>2ecb23b78ad5   jbcodeforce/ibu-insurance-data-mgr:latest  0.0.0.0:8080-&gt;8080/tcp, 8443/tcp         datamgr\n3988ffd617c6   jbcodeforce/athena-owl-backend:latest      0.0.0.0:8000-&gt;8000/tcp                   owl-backend\n258460ed25ed   jbcodeforce/athena-owl-frontend:latest      0.0.0.0:3000-&gt;80/tcp                   owl-frontend\n349f3beb4174   icr.io/cpopen/odm-k8s/odm:8.12             0.0.0.0:9060-&gt;9060/tcp, 9080/tcp, 0.0.0.0:9443-&gt;9443/tcp, 9453/tcp   decisionsvc\n070e124923f7   postgres:latest                            0.0.0.0:5432-&gt;5432/tcp                   postgres\n86052092cfe7   ghcr.io/chroma-core/chroma:latest          0.0.0.0:8005-&gt;8000/tcp                   chroma-db\n</code></pre> <ul> <li>To look at the owl-backend logs</li> </ul> <pre><code>docker logs owl-backend\n</code></pre> <p>Next see the demonstration script section below, or the non-regression tests to validate automatically the demonstration scenario execution.</p>"},{"location":"insurance/#demonstration-flows","title":"Demonstration Flows","text":"<p>The business policies are declared in a semi-structured document, and were extracted using the \"Agile Business Rule Development Methodology\". An extract of this document is shown in the figure below:</p> <p></p> <ul> <li>The business policy 52 is implemented in IBM ODM as the following rule:</li> </ul> <p></p> <p>Which is visible in the Decision Center at the address http://localhost:9060/decisioncenter.</p> <ul> <li>Now to illustrate that using the policy document as input for a Retrieval Augmented Generation will provide limited value to customer support staff's query, you can use the OWL Frontend user's interface at http://localhost:3000/:</li> </ul> <p></p> <p>[Optional]: Once the document is uploaded, you can use the OWL_backend APIs to do a some similarity searches on the document content. The URL for the APIs is http://localhost:8000/docs, while the API for similarity search is in the documents RESTful resource .</p> <ul> <li>Using the following query: \"\" we can see that the LLM with or without RAG does not give the real answer, and also at different time, it returns different answer</li> </ul> <p></p> <ul> <li>Setting the flag to use ODM, give the result according to the rules:</li> </ul> <p></p>"},{"location":"insurance/#validate-the-demo-with-python-code","title":"Validate the demo with python code","text":"<p>Under the <code>e2e</code> folder you can find different tools to support automatic testing:</p> <ul> <li>Create python virtual environment if not created before:</li> </ul> <pre><code>python -m venv .venv\n# for MAC / Linux users\nsource ./venv/bin/activate\n# for Windows\nsource ./venv/Scripts/activate\n</code></pre> <ul> <li>Install needed library to run those tests</li> </ul> <pre><code>cd e2e\npip install -r requirements.txt\n</code></pre> <ul> <li>Run the happy path tests:</li> </ul> <pre><code>cd e2e\npython non_regression_tests.py\n</code></pre>"},{"location":"insurance/#maintenance-activities-for-the-demonstration","title":"Maintenance activities for the demonstration","text":"<ul> <li>It may be relevant to reset the vector store database. To do so, delete the folder with the data content. </li> </ul> <pre><code>cd IBU-insurance-demo/deployment/local\nrm -r data/chromadb\nrm -r data/file_content\n</code></pre> <ul> <li>Restarting the owl-backend. As of now as the backend does not use a database, it loads Owl Entity definitions from file manifests. So sometime it is needed to restart the server using the following commands:</li> </ul> <pre><code>cd IBU-insurance-demo/deployment/local\ndocker stop owl-backend\ndocker-compose up -d   # should restart only the owl-backend\n</code></pre>"},{"location":"insurance/#architecture","title":"Architecture","text":"<p>The high level the architecture for this demonstration looks like in the following figure:</p> <p></p> <ul> <li>A chatbot supports the interactions in natural language queries</li> <li>The assistant server manages the conversation and the integration with the different backends. There are two assistants defined for this demonstration, one using IBM ODM decision service, one without it. </li> </ul>"},{"location":"insurance/#component-definitions","title":"Component Definitions","text":""},{"location":"insurance/#define-the-assistant","title":"Define The Assistant","text":"<p>The assistant needs to do different operations to address queries in the insurance domain. The flow is introduced in the following diagram and implemented using LangGraph API:</p> <p></p> <p>The code supporting this graph is in the IBU_Assistant_LG.py and uses LangGraph API</p> <ul> <li>The first agent, <code>ibu_classify_query_agent</code>,  has a system prompt to assess if the query is about an information query or about a complaint related to an insurance entity. The tools used to support both paths are not the same. The system prompt is <code>classify_query_prompt</code>. The agent is  <code>ibu_classify_query_agent</code></li> </ul> <pre><code>graph.add_node(\"gather_information\", self.process_information_query)\ngraph.add_node(\"process_complaint\", self.process_complaint)\ngraph.add_node(\"activate_tools_for_info\", tool_node_1)\ngraph.add_node(\"activate_tools_for_complaint\", tool_node_2)\n</code></pre> <ul> <li> <p>The gathering information agent is using a prompt to search for information, using query tools to claim or client databases and then external web search. The agent is <code>ibu_tool_rag_agent_limited</code>.</p> </li> <li> <p>The complaint processing agent is <code>ibu_tool_rag_agent</code>.</p> </li> <li>The active tool nodes are taking the output for the LLM to assess the tool selections and then execute those tools, accumulates the responses to send them back to the matching agent. The tool lists are different in each agent:</li> </ul> agents.yaml file in config folder<pre><code>ibu_tool_rag_agent_limited:\n  agent_id: ibu_tool_rag_agent_limited\n  tools:\n    - ibu_client_by_id\n    - ibu_client_by_name\n    - ibu_claim_by_id\n    - tavily\n\n# \nibu_tool_rag_agent:\n   agent_id: ibu_tool_rag_agent\n   tools:\n    - ibu_best_action\n    - ibu_client_by_id\n    - ibu_client_by_name\n    - ibu_claim_by_id\n</code></pre> <p>To navigate in the graph conditions are added to the edges:</p> conditonal edge in IBU_Assistant_LG.py<pre><code># from the gathering information node, if there is a tool call in the response then goes to activate the tools\n graph.add_conditional_edges(\n    \"gather_information\",  # (1)\n    self.route_tools,      # (2)\n    { \n        \"tools\": \"activate_tools_for_info\", \n        END: END\n    }\n )\n</code></pre> <ol> <li> The node with LLM</li> <li> The function to decide where to route</li> </ol> <p>The route tools function looks at the present of tool_calls in the LLM ai message response:</p> route_tools function<pre><code> if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) &gt; 0:\n</code></pre>"},{"location":"insurance/#define-agents","title":"Define Agents","text":""},{"location":"insurance/#ibu_classify_query_agent","title":"ibu_classify_query_agent","text":"<p>The first agent declaration uses the <code>IBUClassifyQueryAgent</code> class.</p> File ibu_backend/src/config/agents.yaml<pre><code>ibu_classify_query_agent:\n  agent_id: ibu_classify_query_agent\n  name: ibu_classify_query_agent\n  description: openai based agent with simple prompt \n  class_name: ibu.llm.agents.ClassifyQueryAgent.IBUClassifyQueryAgent\n  modelClassName: langchain_openai.ChatOpenAI\n  modelName: gpt-3.5-turbo-0125\n  prompt_ref: classify_query_prompt\n  temperature: 0\n  top_k: 1\n  top_p: 1\n</code></pre>"},{"location":"insurance/#ibu_tool_rag_agent","title":"ibu_tool_rag_agent","text":"<p>To illustrate the integration with Vector Store a specific agent: tool_rag_agent is defined.</p> File ibu_backend/src/config/agents.yaml<pre><code>ibu_tool_rag_agent:\n  agent_id: ibu_tool_rag_agent\n  name: ibu_tool_rag_agent\n  description: openai based agent with prompt with query and context\n  class_name: ibu.llm.agents.tool_rag_agent.IbuToolRagAgent\n  modelClassName: langchain_openai.ChatOpenAI\n  modelName: gpt-3.5-turbo-0125\n  prompt_ref: ibu_rag_prompt\n  temperature: 0\n  top_k: 1\n  top_p: 1\n  tools:\n    - ibu_best_action\n    - ibu_client_by_id\n    - ibu_client_by_name\n    - get_claim_status_by_user_name\n    - ibu_claim_by_id\n</code></pre>"},{"location":"insurance/#ibu_tool_rag_agent_limited","title":"ibu_tool_rag_agent_limited","text":"<p>Using the same code as above but with other tools.</p> File ibu_backend/src/config/agents.yaml<pre><code>ibu_tool_rag_agent_limited:\n  agent_id: ibu_tool_rag_agent_limited\n  name: OpenAI IBU agent with RAG Limited\n  description: OpenAI IBU agent with RAG and insurance tool without decision service\n  class_name: ibu.llm.agents.tool_rag_agent.IbuToolRagAgent\n  modelClassName: langchain_openai.ChatOpenAI\n  modelName: gpt-3.5-turbo-0125\n  prompt_ref: ibu_rag_prompt\n  temperature: 0\n  top_k: 1\n  top_p: 1\n  tools:\n    - ibu_client_by_id\n    - ibu_client_by_name\n    - get_claim_status_by_user_name\n    - ibu_claim_by_id\n    - tavily\n</code></pre>"},{"location":"insurance/#define-tools","title":"Define Tools","text":"<p>This is one of the most important exercise. The tools are functions and declarations in manifest file. </p> <p>The get client information by using the first and last names is a function that uses a HTTP client to call the DataManager microservice, using the repository pattern:</p> client_tools.py<pre><code>def get_client_by_name(firstname: str, lastname: str) -&gt; dict:\n    \"\"\"get client information given his or her name\"\"\"\n    return build_or_get_insurance_client_repo().get_client_by_name(firstname, lastname)\n</code></pre> <p>The repository is a Singleton. </p> Declaration in config/tools.yaml<pre><code>ibu_client_by_name:\n  tool_id: ibu_client_by_name\n  tool_name: \"Client by lastname and firstname\"\n  tool_class_name: 'ibu.llm.tools.client_tools'  # (1)\n  tool_description: 'get client information given his or her lastname and firstname'\n  tool_fct_name: get_client_by_name\n</code></pre> <ol> <li>The module file name where the function is implemented</li> </ol>"},{"location":"insurance/#define-instructions","title":"Define instructions","text":"<p>System prompts are defined externally in the prompts.yaml and then referenced in the agent:</p> IBU Classify Query Agent in agents.yaml<pre><code>ibu_classify_query_agent:\n  agent_id: ibu_classify_query_agent\n  name: IBU Classify Query Agent\n  prompt_ref: classify_query_prompt  # (1)\n</code></pre> <ol> <li>Reference to a system prompt.</li> </ol> <p>The matching prompt:</p> Classify the query instructions in prompts.yaml<pre><code>classify_query_prompt:\n  prompt_id:  classify_query_prompt\n  name: Classify the query instructions\n  locales:\n  - locale: en\n    text: &gt;\n      \"You are an expert at extracting intent from user question. Assess if this is a complaint or an information gathering query.\n        The information contains documents related to insurance policies, claim, coverages.\n        Use complaint for questions on insurance claim status or reimbursement or unhappy customer. Only return information or complaint.\"\n</code></pre>"},{"location":"insurance/#development-activities","title":"Development activities","text":""},{"location":"insurance/#prepare-a-virtual-environment","title":"Prepare a virtual environment","text":"<pre><code>python -m venv .venv\n# for MAC / Linux users\nsource ./venv/bin/activate\n# for Windows\nsource ./venv/Scripts/activate\n</code></pre> <p>To run unit tests or integration tests, once the Python virtual environment is started be sure to set the PYTHONPATH environment variable so the athena core module can be found:</p> <pre><code># under ibu_backend\nsource setpython.sh\n</code></pre>"},{"location":"insurance/#run-unit-tests","title":"Run unit tests","text":"<p>All the unit tests are defined with Python unittests library.</p> <pre><code># under ibu_backend\npytest -s tests/ut/\n</code></pre>"},{"location":"insurance/#debug-a-unit-tests","title":"Debug a unit tests","text":"<p>The following instructions are for VScode:</p> <ul> <li>Select the test class as the python file to execute</li> <li> <p>Start the debug and verify the launch configuration includes:</p> <pre><code>\"configurations\": [\n\n    {\n        \"name\": \"Python Debugger: Current File Demos\",\n        \"type\": \"debugpy\",\n        \"request\": \"launch\",\n        \"program\": \"${file}\",\n        \"console\": \"integratedTerminal\",\n        \"env\": { \"PYTHONPATH\": \"${workspaceRoot}/../athena-owl-core/owl-agent-backend/src\"},\n        \"cwd\": \"${workspaceRoot}/IBU-insurance-demo/ibu_backend\"\n    }\n]\n</code></pre> </li> </ul>"},{"location":"insurance/#physical-deployment-of-the-demonstration","title":"Physical deployment of the demonstration","text":"<p>As of now the owl-backend is a container image, deployable as a unit and being  able to mount the python code of the demonstration to run the different orchestration logic. The diagram illustrates those concepts to run on a local machine with the data manager microservice running in its own container</p> <p></p> <p>For production deployment the owl-backend code and the specific logic may be packaged in its own container.</p>"},{"location":"miniloan/","title":"IBM-ODM LoanApp","text":""},{"location":"miniloan/#ibm-miniloan-odm-demonstration-with-agent","title":"IBM Miniloan ODM demonstration with Agent","text":"Version <p>Created 06.2024</p>"},{"location":"miniloan/#goals","title":"Goals","text":"<p>The Miniloan application is part of the IBM Operational Decision Management product and tutorial. The goal of this hybrid AI demonstration is to illustrate how unstructured query in natural language can be decomposed using a LLM to identify parameters to call the loan application decision service and how to do it with the Owl Framework.</p> <p>The end-user's questions that are tested and validated are:</p> <ul> <li>What is the credit score of Robert Smith?: this will demonstrate call to a backend CRM database.</li> <li>My client robert smith wants to borrow $1,000,000 for 180 months  with a yearly repayment of $60,000 do you think it is possible?: will illustrate the call to the miniloan ruleapp using the loan parameters extracted by the LLM.</li> <li>One of our client, Jean Martin, wants a loan for $300,000 for a duration of 180 months and a yearly repayment of $40,000 do we approve it?, just to demonstrate that different rules apply.</li> </ul>"},{"location":"miniloan/#architecture","title":"Architecture","text":"<p>The high level the architecture for this demonstration looks like in the figure below:</p> <p></p> <ul> <li>A chatbot supports the interactions with a customer support representative using natural language queries</li> <li>The assistant server manages the conversation and the integration with different backends. There are two assistants defined for this demonstration, one using IBM ODM MiniLoan decision service, one without it.</li> <li>The Loan App Decision service is the SAMPLE RuleApp deployed in a Rule Execution Server</li> <li>The different microservices to access the client database as future or existing borrowers, and to access the loan applications repository.</li> <li>The LLM is an externally Large Language Model accessible via API. Different models can be used.</li> </ul> <p>To make it easier the loanApp and client the repositories are mockup and loaded in memory.</p> <p>Recall that the rules implemented validate the data on the loan and borrower attributes:</p> <ul> <li>The max amount of money a loan could be:</li> </ul> <p></p> <ul> <li>The minimum credit score the borrower needs to have:</li> </ul> <p></p> <ul> <li>The yearly payment compare to the borrower incomes and credit score as a decision table:</li> </ul> <p></p> <p>Those rule evaluations are key to get reliable answer even if we have to process unstructured text.</p> <p>For more detail on the OWL Core components design see this note.</p>"},{"location":"miniloan/#physical-deployment-of-the-demonstration","title":"Physical deployment of the demonstration","text":"<p>As of now the owl-backend is a container image, deployable as a unit and ables to mount the python code of the demonstration to run the different orchestration logic. The diagram illustrates those concepts to run on a local machine</p> <p></p> <p>For production deployment the owl-backend code and the specific logic may be packaged in its own container.</p>"},{"location":"miniloan/#demonstration-flows","title":"Demonstration Flows","text":"<ul> <li>Get a the API keys for the different LLM you want to use in your solution: WatsonX.AI , OpenAI Anthropic, Mistral, ... and use the <code>/demo_tmpl/.env_tmpl</code> file to persist those API KEYS, rename the file as <code>.env</code> and move it the miniloan demonstration folder.</li> </ul> <pre><code># under IBM-miniloan-demo\ncp ../demo_tmpl/.env_tmpl .env\n</code></pre> <ul> <li>Start the docker compose with all the components of the above architecture.</li> </ul> <pre><code>cd IBM-MiniLoan-demo/deployment/local/\ndocker compose up -d\n</code></pre> <ul> <li>The Frontend user interface is available at http://localhost:3000/, clicking to the gear will bring the setting panel:</li> </ul> <ul> <li>The backend APIs is available at the following URL http://localhost:8000/docs. You do not need to use it for the demonstration scenario but feel free to use to it to understand the OWL entity model.</li> </ul> <ul> <li>Run a demonstration script to validate the deployment and the integration with LLM:</li> </ul> <pre><code># under the e2e folder\npython non_regression_tests.py\n</code></pre> <p>The script validates:</p> <ul> <li>The health if the server end-point</li> <li>Get the default system prompt designed for the demonstration</li> <li>Get the main assistant entity (the metadata about the assistant)</li> <li>Get the loan agent entity</li> <li>Get one of the tool entity to get information from a backend database</li> <li>Makes a unstructured query to ask about one of the existing client: What is the credit score of Robert Smith using IBU loan database?</li> <li>Assess a loan for a borrower with low credit score</li> <li>Assess for a successful loan application</li> </ul>"},{"location":"miniloan/#demonstrating-with-the-user-interface","title":"Demonstrating with the User Interface","text":"<p>The User interface may be used to do a live demonstration:</p> <p>The following figure is using the <code>ibu_assistant_limited</code> assistant to try to answer the question. The tool calling to access the client data is successful but the LLM generates hallucinations:</p> <p></p>"},{"location":"miniloan/#agentic-with-rule-engine","title":"Agentic with Rule Engine","text":"<p>This section explains how to use the OWL framework to support the demonstration. </p> <p>An assistant supports a customer representative to answer questions and queries about a loan. Assistant entity uses an agent, which is linked to the LLM to call via API and the tool definitions.</p> <p></p> <ul> <li>The assistant definition is simple and uses the BaseAssistant class from the Owl framework which uses LangChain's chain construct with or without tools definition.</li> </ul> <pre><code>ibu_assistant:\n  assistant_id: ibu_assistant\n  class_name: athena.llm.assistants.BaseAssistant.BaseAssistant\n  description: A default assistant that uses LLM, and local defined tools like get borrower, and next best action\n  name: IBU Loan App assistant\n  agent_id: ibu_agent\n</code></pre> <p>The assistant without ODM decision service function is:</p> <pre><code>ibu_assistant_limited:\n  assistant_id: ibu_assistant_limited\n  class_name: athena.llm.assistants.BaseAssistant.BaseAssistant\n  description: A default assistant that uses LLM, and local defined tools like get borrower, without decision service\n  name: IBU Loan App assistant\n  agent_id: ibu_agent_limited\n</code></pre> <ul> <li>The agent entity definition lists the prompt, and tools to use, and the LLM model. The <code>langchain_openai.ChatOpenAI</code> class is part of the langchain library. So a class that wraps a specific LLM API can be used.  </li> </ul> <pre><code>ibu_agent:\n  agent_id: ibu_agent\n  name: ibu_agent\n  description: openai based agent with IBU loan app prompt and tools\n  class_name: athena.llm.agents.base_chain_agent.OwlAgent\n  modelName: gpt-3.5-turbo-0125\n  modelClassName: langchain_openai.ChatOpenAI\n  prompt_ref: ibu_loan_prompt\n  tools:\n  - ibu_client_by_name\n  - ibu_loan_assessment_action\n</code></pre> <ul> <li>Tool definition looks to access data about the borrower/ client references the class that implement the tool function. The description is very important and represents a system prompt the LLM will use in the context window to infer the good data extraction from the unstructured query.</li> </ul> <pre><code>ibu_client_by_name:\n  tool_id: ibu_client_by_name\n  tool_class_name: 'ibu.llm.tools.client_tools'\n  tool_description: 'get client information given his or her name'\n  tool_fct_name: get_client_by_name\n</code></pre> <ul> <li>For the decision service, the same approach with a different function name.</li> </ul> <pre><code>ibu_loan_assessment_action:\n  tool_id: ibu_loan_assessment_action\n  tool_class_name: ibu.llm.tools.client_tools\n  tool_description: 'perform the loan application request assessment for the given borrower name'\n  tool_fct_name: assess_loan_app_with_decision\n</code></pre> <p>Assistants, agents and prompts are declarative. Tools need declaration but some code to do the integration. </p>"},{"location":"miniloan/#development-around-the-demonstration","title":"Development around the demonstration","text":"<p>In case you need to work on the current demonstration, and run some of the test cases, this section addresses what needs to be done to run on you own local laptop (or a VM on the cloud) with a Docker engine. Currently, in development mode, the source code of the core framework is needed so you need to clone the github repository ( in the future, we may build a module that should be installable via <code>pip install</code>).</p> <pre><code># for example in $HOME/Code/Athena\n\ngit clone https://github.com/AthenaDecisionSystems/athena-owl-core\n</code></pre>"},{"location":"miniloan/#unit-tests","title":"Unit tests","text":"<ul> <li>Define the PYTHONPATH so the core modules can be accessed during the tests executions:</li> </ul> <pre><code>    export PYTHONPATH=$WHERE_YOUR_CODE_IS/athena-owl-core/owl-agent-backend/src\n</code></pre> <ul> <li>Install specific library for testing</li> </ul> <pre><code># under ibu-backend\npip install -r tests/requirements.txt\n</code></pre> <ul> <li>Run all unit tests for the Miniloan:</li> </ul> <pre><code># under ibu-backend\npytest -s tests/ut\n</code></pre>"},{"location":"miniloan/#integration-tests","title":"Integration tests","text":"<p>For integration tests, you need to start the backend using Docker Compose as explained before, then run all the integration tests via the command:</p> <pre><code># under ibu-backend\npytest -s tests/it\n</code></pre>"},{"location":"miniloan/#code-explanations","title":"Code Explanations","text":"<p>The previous section demonstrates the Yaml manifests for the declaration of the assistant, agent and tools. Each demonstration will have different tools. This section explains the tools implemented in this demonstration which may help for future development.</p>"},{"location":"miniloan/#code-structure","title":"Code structure","text":"<p>Each demonstration is its own folder and includes mostly the same structure:</p> <p></p> Folder Intent decisions/persistence Include the resDB ruleApps from IBM ODM deployment Infrastructure as code and other deployment manifests e2e end to end testing for scenario based testing with all components deployed ibu_backend/src The code for the demo ibu_backend/openapi Any openAPI documents that could be used to generate Pydentic objects. ODM REST ruleset openAPI is used. ibu_backend/config The different configuration files for the Agentic solution entities ibu_backend/tests Unit tests (ut folder) and integration tests (it folder)"},{"location":"miniloan/#focusing-on-tools","title":"Focusing on tools","text":"<p>The tool function coding is done in one class, the client_tools.py. This class implements the different functions to be used as part of the LLM orchestration, and also the factory to build the tool for the LangChain framework.</p> <p>Taking the tool definition below</p> <pre><code>ibu_loan_assessment_action:\n  tool_id: ibu_loan_assessment_action\n  tool_class_name: ibu.llm.tools.client_tools\n  tool_description: 'perform the loan application request assessment for the given borrower name'\n  tool_fct_name: assess_loan_app_with_decision\n</code></pre> <p>The module <code>ibu.llm.tools.client_tools</code> includes the function <code>assess_loan_app_with_decision</code> that exposes the parameters the LLM can extract from the unstructured text and gives back to the langchain chains to perform the tool calling. The code prepares the payload to the ODM service.</p>"},{"location":"miniloan/#future-enhancement","title":"Future enhancement","text":"<p>It is clear that the unstructured query is key to get good tool calling. It is possible to add a ODM rule set for data gathering. Any required data attributes needed to decide on the loan application may be evaluate from what the LLM was able to extract. LLM can build json payload conforms to a schema. Adding an agent to look at the data of the json, will help asking the question to the human to get all the missing data.</p> <p></p>"},{"location":"miniloan/#next","title":"Next","text":"<p>As a next step you can study how to create your own demonstration &gt;&gt;&gt;</p>"}]}